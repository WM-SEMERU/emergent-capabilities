{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364f96dd-8484-431b-b7dc-55521119fb76",
   "metadata": {},
   "source": [
    "# INSTALLING THE TESTS\n",
    "Each test battery is stored as a list of JSON objects formatted as\n",
    "```js\n",
    "{ \"format\": 0 | 1 | 2,\n",
    ", \"name\": \"string\"\n",
    ", ... // other info\n",
    ", \"cases\":\n",
    "  [ { \"prompt\": \"string\"\n",
    "    , \"truth\": Value\n",
    "    }\n",
    "  , ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "with potentially other properties specific to the battery stored in that same object.\n",
    "\n",
    "`\"format\"` corresponds to the enum `BatteryFormat`:\n",
    "\n",
    "```python\n",
    "BatteryFormat = Enum(\n",
    "    \"BatteryFormat\",\n",
    "    [\"FreeText\", \"MultipleChoice\", \"FixedMultipleChoice\"]\n",
    ")\n",
    "```\n",
    "\n",
    "For multiple choice batteries, the choices are provided as a `\"choices\": [\"choice 1\", \"choice 2\", ...]` property stored in the object, and `\"truth\"` is an index.\n",
    "\n",
    "But, multiple choice batteries where the choices are the same across test cases (e.g. boolean), the `\"choices\"` property is omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d3db26-54c6-4364-aef9-787dd7e3a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ad70b0-a176-476a-8b5e-55375d5ab19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatteryFormat = IntEnum(\n",
    "    \"BatteryFormat\",\n",
    "    [\"FreeText\", \"MultipleChoice\", \"FixedMultipleChoice\"]\n",
    ")\n",
    "def save_battery(name, *, fmt, choices=None, gen=None, cases=None):\n",
    "    if cases is None:\n",
    "        assert gen, \"Expected generator when no cases given\"\n",
    "        cases = gen.TestCases()\n",
    "    \n",
    "    json_object = {\n",
    "        \"format\": fmt,\n",
    "        \"name\": name,\n",
    "    }\n",
    "\n",
    "    if fmt == BatteryFormat.FixedMultipleChoice:\n",
    "        assert choices, \\\n",
    "            \"Expected corresponding choices option when creating FixedMultipleChoice battery\"\n",
    "        json_object[\"choices\"] = choices\n",
    "\n",
    "    # put cases last for the sake of json human readability\n",
    "    json_object[\"cases\"] = list(cases)\n",
    "    \n",
    "    content = json.dumps(json_object, separators=(\",\", \":\"))\n",
    "    print(f\"{content[:70]}\\n... {len(content) - 140} bytes omitted ...\\n{content[-70:]}\")\n",
    "    output_path = os.path.join(\"data\", \"compiled\", f\"{name}.json\")\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "290e316a-37c8-4983-b910-7b0459589b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(py_object, fixed=False, file_name=\"task.json\"):\n",
    "    path = os.path.join(*py_object.__path__, file_name)\n",
    "    results = []\n",
    "    fixed_choices = None\n",
    "    with open(path, \"r\") as tasks_file:\n",
    "        data = json.load(tasks_file)\n",
    "        for example in data[\"examples\"]:\n",
    "            # reformat\n",
    "            target_scores = example[\"target_scores\"]\n",
    "            targets = list(target_scores.keys())\n",
    "            \n",
    "            if fixed:\n",
    "                if fixed_choices is None:\n",
    "                    fixed_choices = targets\n",
    "            \n",
    "            if \"target\" in example:\n",
    "                truth = example[\"target\"]\n",
    "                truth = fixed_choices.index(truth)\n",
    "            else:\n",
    "                truth_key = max(target_scores, key=target_scores.get)\n",
    "                truth = targets.index(truth_key)\n",
    "\n",
    "            task_object = {\n",
    "                \"prompt\": example[\"input\"],\n",
    "                \"truth\": truth\n",
    "            }\n",
    "            if not fixed:\n",
    "                task_object[\"targets\"] = targets\n",
    "            \n",
    "            results.append(task_object)\n",
    "    \n",
    "    return fixed_choices, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351bfc4-a81f-4867-b073-37498821d8d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `boolean_expressions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb8a34d-5cb9-4219-9313-c7698e18f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigbench.benchmark_tasks.boolean_expressions import task as be_task\n",
    "import random\n",
    "\n",
    "# we will simply take the tasks, rather than use bigbench's evaluator\n",
    "# this converts the task into a json task\n",
    "class ECBooleanExpressions(be_task.BooleanExpressionsTask):\n",
    "    \"\"\"Extracting boolean expressions task of variable difficulty.\"\"\"\n",
    "\n",
    "    def _generate_expressions(self, expr_size, shots):\n",
    "        expressions = list(self._yield_expression(expr_size))\n",
    "\n",
    "        for shot in shots:\n",
    "            # sort and reshuffle for each shot\n",
    "            expressions = sorted(expressions)\n",
    "            random.shuffle(expressions)\n",
    "            # gather expressions in shot+1 windows\n",
    "            for i in range(0, len(expressions), shot + 1):\n",
    "                *shot_prompts, question = [\n",
    "                    self._eval_expression(expr)\n",
    "                    for expr in expressions[i : i + shot + 1]\n",
    "                ]\n",
    "                if len(shot_prompts) != shot:\n",
    "                    continue\n",
    "                prompt = \"\".join(\n",
    "                    prompt + str(truth) + \" . \"\n",
    "                    for (truth, prompt) in shot_prompts\n",
    "                )\n",
    "                question_truth, question_prompt = question\n",
    "                prompt += question_prompt\n",
    "                yield {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"truth\": int(question_truth),\n",
    "                    \"shot\": shot,\n",
    "                    \"expr_size\": expr_size,\n",
    "                }\n",
    "    \n",
    "    def expressions_for(self, shots=None):\n",
    "        if shots is None:\n",
    "            shots = [self.num_shots]\n",
    "        \n",
    "        for expr_size in self.expression_lengths:\n",
    "            yield from self._generate_expressions(expr_size, shots)\n",
    "\n",
    "    @staticmethod\n",
    "    def TestCases(*, seed=13, shots=[0, 1, 2]):\n",
    "        ecbe = ECBooleanExpressions(seed=seed)\n",
    "        yield from ecbe.expressions_for(shots=shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12fb9a11-e25b-4ad6-93c4-fb6fb48fe401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"format\":3,\"name\":\"boolean_expressions\",\"choices\":[\"False\",\"True\"],\"c\n",
      "... 634321 bytes omitted ...\n",
      "( True and not not not True ) is \",\"truth\":0,\"shot\":2,\"expr_size\":8}]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_battery(\n",
    "    \"boolean_expressions\",\n",
    "    fmt=BatteryFormat.FixedMultipleChoice,\n",
    "    choices=[\"False\", \"True\"],\n",
    "    gen=ECBooleanExpressions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ae777-2d95-41d4-8fae-40fcb5cb85d5",
   "metadata": {},
   "source": [
    "## `code_line_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "312660d9-4354-418f-b572-93b0391c6c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"format\":2,\"name\":\"code_line_description\",\"cases\":[{\"prompt\":\"for i i\n",
      "... 17376 bytes omitted ...\n",
      "mbers\",\"prints 5\",\"returns numbers which are multiples of 10 or 5\"]}]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import bigbench.benchmark_tasks.code_line_description as cld_task\n",
    "choices, cases = load_json(cld_task)\n",
    "save_battery(\n",
    "    \"code_line_description\",\n",
    "    fmt=BatteryFormat.MultipleChoice,\n",
    "    cases=cases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3d284-8481-439e-aa10-ea6515e52e9c",
   "metadata": {},
   "source": [
    "## `color`: `color.hex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e259b345-9118-4cce-a7ee-006caf8eebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"format\":3,\"name\":\"color.hex\",\"choices\":[\"black\",\"blue\",\"brown\",\"gray\n",
      "... 97992 bytes omitted ...\n",
      "most closely matching this HEX representation: #f8b434 ?\",\"truth\":9}]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import bigbench.benchmark_tasks.color.hex as color_hex_task\n",
    "choices, cases = load_json(color_hex_task, fixed=True)\n",
    "save_battery(\n",
    "    \"color.hex\",\n",
    "    fmt=BatteryFormat.FixedMultipleChoice,\n",
    "    choices=choices,\n",
    "    cases=cases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05cda40-ea2c-4da5-8dad-a15412ebcb50",
   "metadata": {},
   "source": [
    "## `geometric_shapes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d324787f-98e4-4ed0-bbc3-a0f40ef594ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"format\":3,\"name\":\"geometric_shapes\",\"choices\":[\"circle\",\"heptagon\",\"\n",
      "... 57587 bytes omitted ...\n",
      "lement <path d=\\\"M 38.35,49.41 L 31.18,9.15\\\"/> draws a \",\"truth\":4}]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import bigbench.benchmark_tasks.geometric_shapes as shapes_task\n",
    "choices, cases = load_json(shapes_task, fixed=True)\n",
    "save_battery(\n",
    "    \"geometric_shapes\",\n",
    "    fmt=BatteryFormat.FixedMultipleChoice,\n",
    "    choices=choices,\n",
    "    cases=cases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf6252-1144-4ca7-8a0d-c13a129c4f25",
   "metadata": {},
   "source": [
    "## `program_synthesis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c5dc8-b790-414b-a68a-93c97ceb4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is more involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fefaf5-4805-4ed2-8c56-5d3c5b79a399",
   "metadata": {},
   "source": [
    "## `python_programming_challenge`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb83798-1e00-49e3-a1c0-3ec6f3ff8ff6",
   "metadata": {},
   "source": [
    "## `semantic_parsing_in_context_sparc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409bafa-31dc-4c92-90fb-d15626850d7b",
   "metadata": {},
   "source": [
    "## `semantic_parsing_spider`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0fe1f-200a-4b25-a43b-1e6f9e8d7e96",
   "metadata": {},
   "source": [
    "## `data4CopynetV3.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb05e50-15ba-4e51-afa6-a4d4f20cde0f",
   "metadata": {},
   "source": [
    "## [https://zenodo.org/records/10491384](https://zenodo.org/records/10491384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84816123-76ab-48b2-8d15-03626bc70fea",
   "metadata": {},
   "source": [
    "## `auto_debugging`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5b9a4-8ae3-4bcc-a68f-c3a7061c2c55",
   "metadata": {},
   "source": [
    "## `color`: `color.hex` (free text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc03b0-0d43-4e89-9e5b-362daaf49c80",
   "metadata": {},
   "source": [
    "## `geometric_shapes` (free text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa3580-2f9b-48a2-890e-755c8b67f5d0",
   "metadata": {},
   "source": [
    "## CoDiSum's data4CopynetV3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05a4da9-75d7-4577-920a-54e9d4d9cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction successful.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "url = \"https://github.com/SoftWiser-group/CoDiSum/raw/master/data4CopynetV3.zip\"\n",
    "\n",
    "output_directory = \"./\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    zip_content = io.BytesIO(response.content)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_content, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_directory)\n",
    "    \n",
    "    print(\"Extraction successful.\")\n",
    "else:\n",
    "    print(f\"Failed to download the zip file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988593ed-4f61-447d-b7fa-278f18229ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file ./data4CopynetV3/difftextV12.json loaded successfully.\n",
      "JSON file ./data4CopynetV3/msgtextV12.json loaded successfully.\n",
      "{\"format\":1,\"name\":\"commit_message_generation_codisum\",\"cases\":[{\"prom\n",
      "... 107692476 bytes omitted ...\n",
      "create(\\\"m\\\");\\n \\n\",\"truth\":\"remove extra - from --match-original\"}]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# put in data dir\n",
    "\n",
    "def read_json_text(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"JSON file not found at path: {json_file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON file: {json_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    print(\"JSON file\", json_path, \"loaded successfully.\") \n",
    "    return json_data\n",
    "\n",
    "VERSION = 12\n",
    "input_path = os.path.join(output_directory, \"data4CopynetV3\", f\"difftextV{VERSION}.json\")\n",
    "output_path = os.path.join(output_directory, \"data4CopynetV3\", f\"msgtextV{VERSION}.json\")\n",
    "\n",
    "inputs = read_json_text(input_path)\n",
    "outputs = read_json_text(output_path)\n",
    "assert len(inputs) == len(outputs), \"Mismatch between input and output test cases\"\n",
    "\n",
    "cases = []\n",
    "for diff, comment in zip(inputs, outputs):\n",
    "    cases.append({\n",
    "        \"prompt\": diff,\n",
    "        \"truth\": comment\n",
    "    })\n",
    "\n",
    "save_battery(\n",
    "    \"commit_message_generation_codisum\", \n",
    "    fmt=BatteryFormat.FreeText,\n",
    "    cases=cases\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
